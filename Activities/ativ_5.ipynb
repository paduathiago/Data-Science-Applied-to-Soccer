{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# [CDAF] Atividade 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nome: Thiago Pádua de Carvalho\n",
    "\n",
    "## Matrícula: 2020007066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Objetivos\n",
    "- Nessa atividade, estou entregando a pipeline inteira do VAEP implementada para os dados do Wyscout das Top 5 ligas.\n",
    "- Para cada subtítulo abaixo, vocês devem explicar o que foi feito e à qual seção/subseção/equação do paper \"Actions Speak Louder than Goals: Valuing Actions by Estimating Probabilities\" ela corresponde. Justifique suas respostas.\n",
    "- Além disso, após algumas partes do código haverão perguntas que vocês devem responder, possivelmente explorando minimamente o que já está pronto.\n",
    "- Por fim, vocês devem montar um diagrama do fluxo de funções/tarefas de toda a pipeline do VAEP abaixo. Esse diagrama deve ser enviado como arquivo na submissão do Moodle, para além deste notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Referências\n",
    "- [1] https://tomdecroos.github.io/reports/kdd19_tomd.pdf\n",
    "- [2] https://socceraction.readthedocs.io/en/latest/api/vaep.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_matches(path):\n",
    "    matches = pd.read_json(path_or_buf=path)\n",
    "    # as informações dos times de cada partida estão em um dicionário dentro da coluna 'teamsData', então vamos separar essas informações\n",
    "    team_matches = []\n",
    "    for i in range(len(matches)):\n",
    "        match = pd.DataFrame(matches.loc[i, 'teamsData']).T\n",
    "        match['matchId'] = matches.loc[i, 'wyId']\n",
    "        team_matches.append(match)\n",
    "    team_matches = pd.concat(team_matches).reset_index(drop=True)\n",
    "\n",
    "    return team_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_players(path):\n",
    "    players = pd.read_json(path_or_buf=path)\n",
    "    players['player_name'] = players['firstName'] + ' ' + players['lastName']\n",
    "    players = players[['wyId', 'player_name']].rename(columns={'wyId': 'player_id'})\n",
    "\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_events(path):\n",
    "    events = pd.read_json(path_or_buf=path)\n",
    "    # pré processamento em colunas da tabela de eventos para facilitar a conversão p/ SPADL\n",
    "    events = events.rename(columns={\n",
    "        'id': 'event_id',\n",
    "        'eventId': 'type_id',\n",
    "        'subEventId': 'subtype_id',\n",
    "        'teamId': 'team_id',\n",
    "        'playerId': 'player_id',\n",
    "        'matchId': 'game_id'\n",
    "    })\n",
    "    events['milliseconds'] = events['eventSec'] * 1000\n",
    "    events['period_id'] = events['matchPeriod'].replace({'1H': 1, '2H': 2})\n",
    "\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_minutes_played_per_game(path):\n",
    "    minutes = pd.read_json(path_or_buf=path)\n",
    "    minutes = minutes.rename(columns={\n",
    "        'playerId': 'player_id',\n",
    "        'matchId': 'game_id',\n",
    "        'teamId': 'team_id',\n",
    "        'minutesPlayed': 'minutes_played'\n",
    "    })\n",
    "    minutes = minutes.drop(['shortName', 'teamName', 'red_card'], axis=1)\n",
    "\n",
    "    return minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leagues = ['England', 'Spain']\n",
    "events = {}\n",
    "matches = {}\n",
    "minutes = {}\n",
    "for league in leagues:\n",
    "    path = f'../data/matches/matches_{league}.json'\n",
    "    matches[league] = load_matches(path)\n",
    "    path = f'../data/events/events_{league}.json'\n",
    "    events[league] = load_events(path)\n",
    "    path = f'../data/minutes_played/minutes_played_per_game_{league}.json'\n",
    "    minutes[league] = load_minutes_played_per_game(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = f'../data/players.json'\n",
    "players = load_players(path)\n",
    "players['player_name'] = players['player_name'].str.decode('unicode-escape')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que foi feito\n",
    "Primeiramente foi feito o carregamento de uma série de dados: jogos da La Liga e Premier League, jogadores, eventos e minutos jogados por jogo. Houve a leitura dos arquivos de dados em json e transformação em dataframes pandas, seguido de um pré processamento para facilitar a conversão em SPADL.\n",
    "\n",
    "Essa seção diz respeito a parte de leitura dos dados e pré processamento, descrito na seção 2.1, a qual trata dos desafios impostos pelos dados de event stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SPADL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import socceraction.spadl as spd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def spadl_transform(events, matches):\n",
    "    spadl = []\n",
    "    game_ids = events.game_id.unique().tolist()\n",
    "    for g in tqdm(game_ids):\n",
    "        match_events = events.loc[events.game_id == g]\n",
    "        match_home_id = matches.loc[(matches.matchId == g) & (matches.side == 'home'), 'teamId'].values[0]\n",
    "        match_actions = spd.wyscout.convert_to_actions(events=match_events, home_team_id=match_home_id)\n",
    "        match_actions = spd.play_left_to_right(actions=match_actions, home_team_id=match_home_id)\n",
    "        match_actions = spd.add_names(match_actions)\n",
    "        spadl.append(match_actions)\n",
    "    spadl = pd.concat(spadl).reset_index(drop=True)\n",
    "\n",
    "    return spadl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [02:39<00:00,  2.38it/s]\n",
      "100%|██████████| 380/380 [02:33<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "spadl = {}\n",
    "for league in leagues:\n",
    "    spadl[league] = spadl_transform(events=events[league], matches=matches[league])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O que foi feito\n",
    "Após o prcessamento inicial dos dados, seguimos para a conversão dos mesmos para o formato SPADL. Para isso, foi criada uma função que recebe os dataframes de jogos e eventos, retornando um dataframe SPADL. Em seguidas chamamos a função dentro de um for para obtermos as ligas desejadas dentro de um dicionário spadl.\n",
    "\n",
    "Há aqui uma relação com a seção 2.2, que define e trata da conversão dos dados para o formato SPADL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from socceraction.vaep import features as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def features_transform(spadl):\n",
    "    spadl.loc[spadl.result_id.isin([2, 3]), ['result_id']] = 0\n",
    "    spadl.loc[spadl.result_name.isin(['offside', 'owngoal']), ['result_name']] = 'fail'\n",
    "\n",
    "    xfns = [\n",
    "        ft.actiontype_onehot,\n",
    "        ft.bodypart_onehot,\n",
    "        ft.result_onehot,\n",
    "        ft.goalscore,\n",
    "        ft.startlocation,\n",
    "        ft.endlocation,\n",
    "        ft.team,\n",
    "        ft.time,\n",
    "        ft.time_delta\n",
    "    ]\n",
    "\n",
    "    features = []\n",
    "    for game in tqdm(np.unique(spadl.game_id).tolist()):\n",
    "        match_actions = spadl.loc[spadl.game_id == game].reset_index(drop=True)\n",
    "        match_states = ft.gamestates(actions=match_actions)\n",
    "        match_feats = pd.concat([fn(match_states) for fn in xfns], axis=1)\n",
    "        features.append(match_feats)\n",
    "    features = pd.concat(features).reset_index(drop=True)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1 - O que a primeira e a segunda linhas da função acima fazem? Qual sua hipótese sobre intuito dessas transformações? Como você acha que isso pode impactar o modelo final?\n",
    "\n",
    "A primeira e segunda linha do programa acima são filtros do dataframe spadl passados como parâmetro. \\\n",
    "Ambas tratam de remover as classificações de offside e owngoal do dataframe, tornando-as fails. A primeira troca 'result-id's de 2 e 3 para 0 e a segunda troca 'offside' e 'owngoal' por fail. \n",
    "\n",
    "Minha hipótese é que essas alterações foram feitas com o intuito de refinar os dados para a aplicação do modelo, uma vez que as classificações removidas não são tão relevantes para a análise de valor de ação e ambas podem ser abstraídas para falhas sem alterar negativamente o resultado final. \n",
    "\n",
    "O impacto no modelo final será a remoção de dados que não são relevantes para a análise de valor de ação, o que pode tornar o modelo mais preciso. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:12<00:00, 31.49it/s]\n",
      "100%|██████████| 380/380 [00:10<00:00, 34.79it/s]\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "for league in ['England', 'Spain']:\n",
    "    features[league] = features_transform(spadl[league])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que foi feito\n",
    "Definiu-se aqui a função responsável por obter as features que serão inseridas no modelo baseada no dataframe em formato SPADL. features_transform faz um tratamento dos dados, tornando todos os tipos de resultados de ação binários e se utiliza da técnica de one-hot encoding para gerar colunas no dataframe resultante para cada jogo.\n",
    "\n",
    "O processo está descrito na seção 4.1, que trata da definição das features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import socceraction.vaep.labels as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labels_transform(spadl):\n",
    "    yfns = [lab.scores, lab.concedes]\n",
    "\n",
    "    labels = []\n",
    "    for game in tqdm(np.unique(spadl.game_id).tolist()):\n",
    "        match_actions = spadl.loc[spadl.game_id == game].reset_index(drop=True)\n",
    "        labels.append(pd.concat([fn(actions=match_actions) for fn in yfns], axis=1))\n",
    "\n",
    "    labels = pd.concat(labels).reset_index(drop=True)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:15<00:00, 23.96it/s]\n",
      "100%|██████████| 380/380 [00:15<00:00, 24.57it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "for league in ['England', 'Spain']:\n",
    "    labels[league] = labels_transform(spadl[league])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7553"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['England']['scores'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2313"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['England']['concedes'].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2- Explique o porquê da quantidade de labels positivos do tipo scores ser muito maior que do concedes. Como você acha que isso pode impactar o modelo final?\n",
    "Intuitivamente, podemos entender que a quantidade de labels positivos do tipo scores é maior do que a do tipo concedes porque as jogadas ofensivas são melhores construídas, isto é, necessitam de um maior número de estados para se concretizar em gol, enquanto que ações do time com a posse se tornarem gols concedidos podem vir de um número muito menor de estados, como um simples passe errado entre os zagueiros. Podemos ainda afirmar que é menos frequente que essas ações, ditas erros, aconteçam do que investidas de ataque bem sucedidas.\n",
    "\n",
    "Isso pode impactar o modelo final porque, como a quantidade de labels positivos do tipo scores é muito maior que do concedes, o modelo pode acabar tendo um viés positivo para classificar gols em ações ofensivas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que foi feito\n",
    "Aqui é tratado o problema descrito na seção 4.1 de obter labels para cada ação do jogo baseada no estado corrente. \"lab.scores\", assinala o valor 1 para ações que resultam em gol para o time com a posse em até k futuras ações - nesse caso K=10 - e 0 para as demais. \"lab.concedes\" faz o contrário, assinalando 1 para ações que resultam em tomar um gol e 0 para as demais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import sklearn.metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_vaep(X_train, y_train, X_test, y_test):\n",
    "    models = {}\n",
    "    for m in ['scores', 'concedes']:\n",
    "        models[m] = xgb.XGBClassifier(random_state=0, n_estimators=50, max_depth=3)\n",
    "\n",
    "        print('training ' + m + ' model')\n",
    "        models[m].fit(X_train, y_train[m])\n",
    "\n",
    "        p = sum(y_train[m]) / len(y_train[m])\n",
    "        base = [p] * len(y_train[m])\n",
    "        y_train_pred = models[m].predict_proba(X_train)[:, 1]\n",
    "        train_brier = mt.brier_score_loss(y_train[m], y_train_pred) / mt.brier_score_loss(y_train[m], base)\n",
    "        print(m + ' Train NBS: ' + str(train_brier))\n",
    "        print()\n",
    "\n",
    "        p = sum(y_test[m]) / len(y_test[m])\n",
    "        base = [p] * len(y_test[m])\n",
    "        y_test_pred = models[m].predict_proba(X_test)[:, 1]\n",
    "        test_brier = mt.brier_score_loss(y_test[m], y_test_pred) / mt.brier_score_loss(y_test[m], base)\n",
    "        print(m + ' Test NBS: ' + str(test_brier))\n",
    "        print()\n",
    "\n",
    "        print('----------------------------------------')\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training scores model\n",
      "scores Train NBS: 0.8452154331687597\n",
      "\n",
      "scores Test NBS: 0.850366923253325\n",
      "\n",
      "----------------------------------------\n",
      "training concedes model\n",
      "concedes Train NBS: 0.964463215550682\n",
      "\n",
      "concedes Test NBS: 0.9745272575372074\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = train_vaep(X_train=features['England'], y_train=labels['England'], X_test=features['Spain'], y_test=labels['Spain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3 - Por que treinamos dois modelos diferentes? Por que a performance dos dois é diferente?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que foi feito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_predictions(features, models):\n",
    "    preds = {}\n",
    "    for m in ['scores', 'concedes']:\n",
    "        preds[m] = models[m].predict_proba(features)[:, 1]\n",
    "    preds = pd.DataFrame(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = {}\n",
    "preds['Spain'] = generate_predictions(features=features['Spain'], models=models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que foi feito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Action Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import socceraction.vaep.formula as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_action_values(spadl, predictions):\n",
    "    action_values = fm.value(actions=spadl, Pscores=predictions['scores'], Pconcedes=predictions['concedes'])\n",
    "    action_values = pd.concat([\n",
    "        spadl[['original_event_id', 'action_id', 'game_id', 'start_x', 'start_y', 'end_x', 'end_y', 'type_name', 'result_name', 'player_id']],\n",
    "        predictions.rename(columns={'scores': 'Pscores', 'concedes': 'Pconcedes'}),\n",
    "        action_values\n",
    "    ], axis=1)\n",
    "\n",
    "    return action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_values = {}\n",
    "action_values['Spain'] = calculate_action_values(spadl=spadl['Spain'], predictions=preds['Spain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4 - Explore as ações com Pscores >= 0.95. Por que elas tem um valor tão alto? As compare com ações do mesmo tipo e resultado opostado. Será que o modelo aprende que essa combinação de tipo de ação e resultado está diretamente relacionado à variável y que estamos tentando prever?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Qual formula do paper corresponde à coluna 'offensive_value' do dataframe action_values? E a coluna 'defensive_value'?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que foi feito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Player Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_minutes_per_season(minutes_per_game):\n",
    "    minutes_per_season = minutes_per_game.groupby('player_id', as_index=False)['minutes_played'].sum()\n",
    "\n",
    "    return minutes_per_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minutes_per_season = {}\n",
    "minutes_per_season['Spain'] = calculate_minutes_per_season(minutes['Spain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_player_ratings(action_values, minutes_per_season, players):\n",
    "    player_ratings = action_values.groupby(by='player_id', as_index=False).agg({'vaep_value': 'sum'}).rename(columns={'vaep_value': 'vaep_total'})\n",
    "    player_ratings = player_ratings.merge(minutes_per_season, on=['player_id'], how='left')\n",
    "    player_ratings['vaep_p90'] = player_ratings['vaep_total'] / player_ratings['minutes_played'] * 90\n",
    "    player_ratings = player_ratings[player_ratings['minutes_played'] >= 600].sort_values(by='vaep_p90', ascending=False).reset_index(drop=True)\n",
    "    player_ratings = player_ratings.merge(players, on=['player_id'], how='left')\n",
    "    player_ratings = player_ratings[['player_id', 'player_name', 'minutes_played', 'vaep_total', 'vaep_p90']]\n",
    "\n",
    "    return player_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_ratings = {}\n",
    "player_ratings['Spain'] = calculate_player_ratings(action_values=action_values['Spain'], minutes_per_season=minutes_per_season['Spain'], players=players)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 6 - Acha que o Top 5 da lista é bem representativo? Compare esse ranqueamento do VAEP com o do xT da Atividade 4. Qual você acha que é mais representativo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que foi feito"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
